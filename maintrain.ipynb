{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import normalize, to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "image_directory = 'datasets/'\n",
    "no_tumor_images = os.listdir(image_directory + 'no/')\n",
    "yes_tumor_images = os.listdir(image_directory + 'yes/')\n",
    "\n",
    " \n",
    "\n",
    "# Preprocess dataset\n",
    "dataset = []\n",
    "label = []\n",
    "INPUT_SIZE = 224  # Adjusted for transfer learning compatibility\n",
    "\n",
    "def load_images(image_list, label_value, folder):\n",
    "    for image_name in image_list:\n",
    "        if image_name.endswith('.jpg'):\n",
    "            image_path = os.path.join(image_directory, folder, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image, (INPUT_SIZE, INPUT_SIZE))\n",
    "                dataset.append(img_to_array(image))\n",
    "                label.append(label_value)\n",
    "\n",
    " \n",
    "\n",
    "# Load images\n",
    "load_images(no_tumor_images, 0, 'no')\n",
    "load_images(yes_tumor_images, 1, 'yes')\n",
    "\n",
    " \n",
    "\n",
    "# Convert to NumPy arrays\n",
    "dataset = np.array(dataset, dtype=np.float32) / 255.0  # Normalize\n",
    "label = np.array(label)\n",
    "\n",
    " \n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, label, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    " \n",
    "\n",
    "\n",
    "# Build CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(INPUT_SIZE, INPUT_SIZE, 3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "cnn_model.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_test, y_test))\n",
    "cnn_model.save('BrainTumor_CNN.h5')\n",
    "\n",
    "# Build Transfer Learning Model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(INPUT_SIZE, INPUT_SIZE, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "transfer_model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "transfer_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "transfer_model.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_test, y_test))\n",
    "transfer_model.save('BrainTumor_TransferLearning.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
